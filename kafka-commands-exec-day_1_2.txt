	

---------------------------------------

kafka download:

wget https://archive.apache.org/dist/kafka/3.6.0/kafka_2.12-3.6.0.tgz --no-check-certificate


tar -xvf kafka_2.12-3.6.0.tgz

mkdir -p /tmp/zookeeper1
mkdir -p /tmp/zookeeper2
mkdir -p /tmp/zookeeper3

chmod 777 -R /tmp/zookeeper1
chmod 777 -R /tmp/zookeeper2
chmod 777 -R /tmp/zookeeper3

echo "1" >> /tmp/zookeeper1/myid


-------------------

echo "2" >>  /tmp/zookeeper2/myid

------------
echo "3" >> /tmp/zookeeper3/myid

-------------

cd /root/kafka_2.12-3.6.0/configcd

vi zookeeper1.properties

dataDir=/tmp/zookeeper1
clientPort=2181
admin.enableServer=true
admin.serverPort=8080
tickTime=2000
initLimit=5
syncLimit=2
server.1=localhost:2888:3888
server.2=localhost:2989:3088
server.3=localhost:3089:3188
autopurge.snapRetainCount=3
autopurge.purgeInterval=24


cp zookeeper1.properties zookeeper2.properties 
cp zookeeper1.properties zookeeper3.properties 

vi zookeeper2.properties 
dataDir=/tmp/zookeeper2
clientPort=2182
admin.enableServer=false

vi zookeeper3.properties 
dataDir=/tmp/zookeeper3
clientPort=2183
admin.enableServer=false
---------------------

To start the zookeeper 


cd /root/kafka_2.12-3.6.0/bin

nohup ./zookeeper-server-start.sh ../config/zookeeper1.properties &
nohup ./zookeeper-server-start.sh ../config/zookeeper2.properties &

nohup ./zookeeper-server-start.sh ../config/zookeeper3.properties &
-------------------------------------------------------
echo srvr |nc localhost 2181 | grep Mode
echo srvr |nc localhost 2182 | grep Mode
echo srvr |nc localhost 2183 | grep Mode
------------------------------------------
cd /root/kafka_2.12-3.6.0/config


vi server1.properties
broker.id=10
listeners=PLAINTEXT://192.168.227.128:9092
log.dirs=/tmp/kafka1
num.partitions=4
min.insync.replicas=2
default.replication.factor=3
offsets.topic.replication.factor=2
transaction.state.log.replication.factor=2
transaction.state.log.min.isr=2
log.flush.interval.messages=10000
log.flush.interval.ms=1000
log.retention.hours=168
blog.segment.bytes=1073741824
zookeeper.connect=localhost:2181,localhost:2182,localhost:2183
group.initial.rebalance.delay.ms=5000
auto.leader.rebalance.enable=true
compression.type=lz4
delete.topic.enable=true
message.max.bytes=1048588
broker.rack=RC1
-----------------------------

cp server1.properties server2.properties
cp server1.properties server3.properties
cp server1.properties server4.propert

vi server2.properties
broker.id=20
listeners=PLAINTEXT://localhost:9093
log.dirs=/tmp/kafka2


vi server3.properties 
broker.id=30
listeners=PLAINTEXT://localhost:9094
log.dirs=/tmp/kafka3
broker.rack=RC2

vi server4.properties 
broker.id=40
listeners=PLAINTEXT://localhost:9095
log.dirs=/tmp/kafka4
broker.rack=RC2

mkdir -p /tmp/kafka1
mkdir -p /tmp/kafka2
mkdir -p /tmp/kafka3
mkdir -p /tmp/kafka4

chmod -R 777 /tmp/kafka1
chmod -R 777 /tmp/kafka2
chmod -R 777 /tmp/kafka3
chmod -R 777 /tmp/kafka4
----------------------------------------------

cd /home/rps/kafka_2.12-3.6.0/bin
 
----------------------- 
nohup ./kafka-server-start.sh ../config/server1.properties &
nohup ./kafka-server-start.sh ../config/server2.properties &
nohup ./kafka-server-start.sh ../config/server3.properties & 
nohup ./kafka-server-start.sh ../config/server4.properties &

// to get to ActiveContoller ID:
./zookeeper-shell.sh localhost:2181 get /controller

//to get all the brokers ids:

./zookeeper-shell.sh  localhost:2181 ls /brokers/ids
--------------------------------------

//to create a topic "demo1"

./kafka-topics.sh --create --topic demo1 --bootstrap-server localhost:9093,localhost:9095

//to list all the topics
./kafka-topics.sh --list --bootstrap-server localhost:9093,localhost:9095

./kafka-topics.sh --describe --topic demo1 --bootstrap-server localhost:9093,localhost:9095

//to discribe the topic
./kafka-topics.sh --create --topic demo2 --partitions 2  --bootstrap-server localhost:9093,localhost:9095

./kafka-topics.sh --create --topic demo3 --partitions 2 --replication-factor 2 --bootstrap-server localhost:9093,localhost:9095 --config max.message.bytes=2096588



./kafka-topics.sh --describe --topic demo2 --bootstrap-server localhost:9093,localhost:9095

./kafka-topics.sh --describe --topic demo3 --bootstrap-server localhost:9093,localhost:9095

./kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo1 --property parse.key=true --property key.separator=:

>1:msg1
>2:msg2
-------------------
./kafka-console-consumer.sh --topic demo1 --bootstrap-server localhost:9092 --partition 3 --offset 0 --property print.key=true --property print.timestamp=true --property print.offset=true


----------------------------------------


Day 2:

How to disable firewaddD

su root
password: redhat

systemctl disable firewalld
systemctl stop firewalld

How to find and kiill the process

ps -ef|grep server1.properties

kill -9 process_ID

ps -ef|grep server2.properties

kill -9 process_ID


ps -ef|grep server3.properties

kill -9 process_ID

ps -ef|grep server4.properties

kill -9 process_ID

------------------------------------

./kafka-topics.sh --create --topic demo1 --bootstrap-server 192.168.162.128:9092
./kafka-topics.sh --describe --topic demo1 --bootstrap-server 192.168.162.128:9092
./kafka-topics.sh --create --topic demo2  --partitions 2 --replication-factor 2 --bootstrap-server 192.168.162.128:9092
./kafka-topics.sh --describe --topic demo2 --bootstrap-server 192.168.162.128:9092

./kafka-topics.sh --list --bootstrap-server 192.168.162.128:9092

 ./kafka-console-producer.sh --topic demo1 --bootstrap-server 192.168.162.128:9092
 
./kafka-console-consumer.sh --topic demo1 --from-beginning  --bootstrap-server 192.168.162.128:9092 --property print.partition=true --property print.offset=true

./kafka-console-consumer.sh --topic demo1 --partition 3 --offset 0 --bootstrap-server 192.168.162.128:9092


./kafka-topics.sh --create --topic sensor --partitions 10 --bootstrap-server 192.168.227.128:9092

How to disable firewalld on linux?

systemctl disable firewalld
systemctl stop firewalld 

./kafka-configs.sh --entity-type topics --entity-name demo1 --alter --add-config min.insync.replicas=1 --bootstrap-server 192.168.162.128:9092
---------------------------
./kafka-topics.sh --create --topic sensor --partitions 10 --bootstrap-server 192.168.162.128:9092

SensorProducer >> change the IP address and run
---------------------------------------
SensorPartitioner
-------------------------
SupplierProducer>> change the IP address and run

SupplierConsumer >> change the IP address and run
------------------------------------
JsonProducer >> change the IP address and run
JsonConsumer >> change the IP address and run  demo5 grp1

-----------------------------------------------
SimpleConsumer>> demo1: change the IP address and run

SimpleConsumerDup>> demo1change the IP address and run

./kafka-consumer-groups.sh --describe --group walmartJavaApp2 --bootstrap-server 192.168.162.128:9092




 ./kafka-consumer-groups.sh --describe --group walmartJavaApp2 --bootstrap-server 192.168.227.128:9092

----------

./kafka-consumer-groups.sh --describe --group  walmartJavaApp2 --bootstrap-server 192.168.227.128:9092

./kafka-consumer-groups.sh --topic demo1  --group walmartJavaApp2 --bootstrap-server 192.168.227.128:9092 --reset-offsets -to-offset 2 --execute 

./kafka-consumer-groups.sh --topic demo1  --group walmartJavaApp2 --bootstrap-server 192.168.227.128:9092 --reset-offsets --shift-by 15 --execute



--shift-by <positive_or_negative_integer>
--to-current
--to-latest
--to-offset <offset_integer>
--to-datetime <datetime_string>
--by-duration <duration_string>

---------------------------------

1. First we need mention all the configuration attributes in the below file:

cd /home/rps/kafka_2.12-3.6.0/bin

sudo vi ../config/connect-file-source.properties

name=local-file-source-mukesh
connector.class=FileStreamSource
tasks.max=2
errors.tolerance=all
errors.retry.delay.max.ms=60000
errors.retry.timeout=5000
file=/home/rps/test.txt
topic=connect-test
transforms=MakeMap,InsertSource
transforms.MakeMap.type=org.apache.kafka.connect.transforms.HoistField$Value
transforms.MakeMap.field=record
transforms.InsertSource.type=org.apache.kafka.connect.transforms.InsertField$Value
transforms.InsertSource.static.field=company_name
transforms.InsertSource.static.value=FMR
-------------------------------------------
sudo vi ../config/connect-standalone.properties

bootstrap.servers=192.168.227.128:9092,192.168.227.128:9093
key.converter.schemas.enable=false
value.converter.schemas.enable=false
offset.storage.file.filename=/home/rps/connect.offsets
plugin.path=/home/rps/kafka_2.12-3.6.0/libs
----------------------------------------------
Start the kafka-connect:
cd /home/rps/kafka_2.12-3.6.0/bin

./connect-standalone.sh ../config/connect-standalone.properties ../config/connect-file-source.properties

---------------------------------
echo "message1">> /home/rps/test.txt
echo "message2">> /home/rps/test.txt
echo "message3">> /home/rps/test.txt
-------------------------------------------------------
let's check the topic

./kafka-topics.sh --list --bootstrap-server 192.168.227.128:9092

./kafka-console-consumer.sh --topic connect-test --from-beginning --bootstrap-server 192.168.227.128:9092


